{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykładowe rozwiązania\n",
    "\n",
    "1. Pobierz *Alice's Adventures in Wonderland* Lewis Carroll z [tego adresu](http://www.gutenberg.org/files/11/11-0.txt)\n",
    "1. Przeczytaj plik używając Pythona; zobacz [dokumentację](https://docs.python.org/3/tutorial/inputoutput.html)\n",
    "1. Zlicz wystąpienia liter w utworze (★ wykluczając nagłówek i stopkę w pliku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pobranie pliku z sieci\n",
    "!wget http://www.gutenberg.org/files/11/11-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# słownik do zliczania liter\n",
    "letters = dict()\n",
    "# analizujemy plik linia po linii\n",
    "with open(\"11-0.txt\") as file:\n",
    "    for line in file:\n",
    "        for char in line:\n",
    "            if not char.isalpha():\n",
    "                continue\n",
    "            char = char.upper()\n",
    "            if char in letters:\n",
    "                letters[char] += 1\n",
    "            else:\n",
    "                letters[char] = 1\n",
    "print(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analogiczne rozwiązanie wykorzystujące defaultdict\n",
    "from collections import defaultdict\n",
    "\n",
    "# domyślna wartość\n",
    "def default_value():\n",
    "    return 0\n",
    "\n",
    "\n",
    "# słownik do zliczania liter z domyślną wartością\n",
    "letters = defaultdict(default_value) # lub = defaultdict(lambda: 0)\n",
    "# analizujemy plik linia po linii\n",
    "with open(\"11-0.txt\") as file:\n",
    "    for line in file:\n",
    "        for char in line:\n",
    "            if not char.isalpha():\n",
    "                continue\n",
    "            char = char.upper()\n",
    "            # nie ma potrzeby sprawdzania czy litera jest już w słowniku\n",
    "            letters[char] += 1\n",
    "print(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# słownik do zliczania liter\n",
    "letters = dict()\n",
    "# flaga wskazująca czy analizujemy tekst książki\n",
    "is_book = False\n",
    "# analizujemy plik linia po linii\n",
    "with open(\"11-0.txt\") as file:\n",
    "    for line in file:\n",
    "        # przełączenie flagi po napotkaniu znacznika nagłówka/końca książki\n",
    "        if line.startswith('*** '):\n",
    "            is_book = not is_book\n",
    "            continue\n",
    "        if not is_book:\n",
    "            continue\n",
    "        for char in line:\n",
    "            if not char.isalpha():\n",
    "                continue\n",
    "            char = char.upper()\n",
    "            if char in letters:\n",
    "                letters[char] += 1\n",
    "            else:\n",
    "                letters[char] = 1\n",
    "print(letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ile słów występuje w utworze?\n",
    "1. Zlicz wystąpienia unikalnych słów (skorzystaj z pakietu `re` i metody `findall`)\n",
    "1. Ile unikalnych słów występuje w utworze?\n",
    "1. Które słowo występuje najczęściej?\n",
    "1. Jakimi częściami tekstu (w procentach) jest kolejnych pięć najczęściej występujących słów?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zliczanie słów z użyciem split\n",
    "total_words = 0\n",
    "with open('11-0.txt') as file:\n",
    "    for line in file:\n",
    "        for word in line.strip().split():\n",
    "            total_words += 1\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# zliczanie słów\n",
    "total_words = 0\n",
    "with open(\"11-0.txt\") as file:\n",
    "    for line in file:\n",
    "        for word in re.findall(r'\\w+', line):\n",
    "            total_words += 1\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metoda `split` nie radzi sobie z wyrażeniami w których użyte zostały znaki przystankowe (zostały one złączone ze słowami)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# zliczanie słów bez dodatkowej pętli\n",
    "total_words = 0\n",
    "with open(\"11-0.txt\") as file:\n",
    "    for line in file:\n",
    "        total_words += len(re.findall(r'\\w+', line))\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# słownik do zliczania unikalnych słów\n",
    "words = dict()\n",
    "with open(\"11-0.txt\") as file:\n",
    "    for line in file:\n",
    "        for word in re.findall(r'\\w+', line.lower()):\n",
    "            if word in words:\n",
    "                words[word] += 1\n",
    "            else:\n",
    "                words[word] = 1\n",
    "# słownik unikalnych słów\n",
    "print(words)\n",
    "# liczba wpisów (kluczy) w słowniku\n",
    "print(len(words))\n",
    "# suma wartości dla kluczy słownika\n",
    "print(sum(words.values()))\n",
    "# największa liczba wystąpień\n",
    "print(max(words.values()))\n",
    "# najczęściej występujące słowo\n",
    "print(list(words.keys())[list(words.values()).index(max(words.values()))])\n",
    "print([word for word, occurrences in words.items() if occurrences == max(words.values())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pięć najczęściej występujących słów (posortowania lista wartości i kluczy ze słownika)\n",
    "words_sorted = sorted([(value, key) for (key, value) in words.items()], reverse = True)\n",
    "five_common = words_sorted[:5]\n",
    "print(five_common)\n",
    "for word in five_common:\n",
    "    print(f'{word[1]}\\t{word[0]*100.0/total_words:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można zaznajomić się z pakietem [heapq](https://docs.python.org/3/library/heapq.html), który dostarcza implementacji funkcji `nlargest`. `sorted` umożliwia również bezpośrednie podanie klucza według którego mają być posortowane dane (parametr `key`), ale ta implementacja pozwoliła na uniknięcie użycia `lambda`, której jeszcze nie znamy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ile unikalnych słów wypełnia połowę całego tekstu?\n",
    "1. ★ Narysuj zależność w skali logarytmicznej pomiędzy rangą słowa a częstotliwością jego występowania (ranga to liczby 1, 2, 3, ... przyporządkowane kolejno najczęściej występującym słowom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ile słów wypełnia połowę całego tekstu\n",
    "# zlicza wystąpienia najczęściej występujących słów, aż do przekroczenia połowy\n",
    "total = 0\n",
    "i = 0\n",
    "for word in words_sorted:\n",
    "    total += word[0]\n",
    "    if (total > total_words / 2):\n",
    "        break\n",
    "    i += 1\n",
    "print(total)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wykres ranga - częstotliwość (pakiety numpy i matplotlib)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# specjalna komenda, która powoduje wklejanie wykresu do notebooka\n",
    "%matplotlib inline\n",
    "rank = np.arange(1, len(words_sorted) + 1) # ranga to kolejne liczby naturalne\n",
    "# częstotliwość to iloraz liczby wystąpień słowa i wszystkich słów\n",
    "freq = np.array(words_sorted)[:,0].astype(float) / total_words\n",
    "plt.loglog(rank, freq);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nim przystąpimy do implementacji warto sprawdzić czy nie istnieje pakiet implementujący dany algorytm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, urllib.request\n",
    "from collections import Counter\n",
    "# pobranie książki\n",
    "response = urllib.request.urlopen('http://www.gutenberg.org/files/11/11-0.txt')\n",
    "data = response.read()\n",
    "text = data.decode('utf-8')\n",
    "# lista słów\n",
    "words = re.findall(r'\\w+', text.lower())\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odnalezienie najczęstszego słowa\n",
    "Counter(words).most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odnalezienie pięciu najczęstszych słów oraz częstotliwości ich występowania\n",
    "five_common = Counter(words).most_common(5)\n",
    "print(five_common)\n",
    "for word in five_common:\n",
    "    print(f'{word[0]}\\t{word[1]*100.0/len(words):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
